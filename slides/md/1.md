---
theme: seriph
background: https://cover.sli.dev
title: Report Cover
info: |
  ## Slidev Template
  Presentation slides for papers.
class: text-center
drawings:
  persist: false
transition: slide-left
mdc: true
export:
  format: pdf
  timeout: 600000 
---

## Do LLMs Strategically Reveal, Conceal, and Infer Information? A Theoretical and Empirical Analysis in The Chameleon Game
- Mustafa O. Karabag,Ufuk Topcu
- 2025-01-31
---
transition: fade-out
---

# Table of Contents
<Toc text-sm minDepth="1" maxDepth="2" />
---
transition: slide-right
---

# Problem Statement
The study addresses the challenge of evaluating whether Large Language Models (LLMs) can strategically manage information in non-cooperative settings. Specifically, it investigates LLMs' abilities to conceal information from adversaries, reveal information to allies, and infer the characteristics of other agents. The primary issue is identifying the strengths and weaknesses of LLMs like GPT-4, Gemini 1.5, and Claude 3.5 Sonnet in effectively handling these tasks within strategic interactions.

---

# Key Approach
The authors utilize the hidden-identity board game, The Chameleon, to empirically and theoretically analyze the information control and decision-making capabilities of LLMs. The game serves as a simulation where LLMs, both as chameleon and non-chameleon agents, must strategically reveal and conceal information. Theoretical analysis of a spectrum of strategies provides bounds on the non-chameleons’ winning probability, examining both concealing and revealing strategies.

---
transition: slide-up
level: 2
---

# Key Steps/Models
The methodology involves several stages:
1. Initial setup of The Chameleon game where non-chameleons share a secret word, known only to them, while the chameleon tries to guess it.
2. LLMs play as both chameleon and non-chameleons, providing responses and making decisions based on their roles.
3. Theoretical analysis of diverse strategies from a spectrum of revealing and concealing tactics.
4. Empirical evaluation of popular LLMs like GPT-3.5, GPT-4, GPT-4o, Gemini 1.5, and Sonnet 3.5.

Each stage determines how well these models handle the balance of revealing enough to signal allies while concealing critical information from the adversary.

---
transition: slide-up
level: 2
---

# Dataset 
The work doesn't rely on a traditional dataset but utilizes the gameplay mechanics of The Chameleon as the data source. The game’s setup involves a group of words and a secret on which the non-chameleons agree while a chameleon tries to deduce the secret based on the group's provided clues. The size and complexity of the dataset are controlled by the number of words and rounds of gameplay used in the experiments.

---

# Evaluation 
The evaluation process includes both theoretical bounds and empirical performance metrics. Non-chameleons’ winning probability bounds are calculated under various strategies. Empirically, the LLMs' ability to correctly identify the chameleon and conceal the secret from it is measured. The winning probability of non-chameleon LLM agents is compared to trivial strategies to assess effectiveness.

---

# Conclusion
The study concludes that current LLMs like GPT-4, Gemini 1.5, and Claude 3.5 Sonnet are inadequate for strategic interactions requiring fine-tuned information control. While these models can identify adversaries, they excessively reveal information, compromising their strategic efficacy. Future work could focus on enhancing LLMs' ability to balance information revealing and concealing dynamics, improving their application in negotiation and other adversarial scenarios.

---
class: px-20
---